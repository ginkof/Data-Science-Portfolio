{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plotly_tree_fn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scikit-learn DecisionTree with Plotly (no matplotlib)\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_tree_plotly(clf, feature_names=None, class_names=None, max_depth=None, precision=2, filled=True, node_size=14, height=600, width=1000):\n",
    "    \"\"\"\n",
    "    Plot a scikit-learn DecisionTreeClassifier/Regressor using Plotly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : fitted DecisionTreeClassifier or DecisionTreeRegressor\n",
    "    feature_names : list[str] | None\n",
    "        Names for features; defaults to indices if None.\n",
    "    class_names : list[str] | None\n",
    "        Optional class names for classifiers; inferred from clf.classes_ if None.\n",
    "    max_depth : int | None\n",
    "        Limit the depth displayed.\n",
    "    precision : int\n",
    "        Digits for thresholds and impurity.\n",
    "    filled : bool\n",
    "        If True, color leaf nodes by predicted class/value.\n",
    "    node_size : int\n",
    "        Marker size for nodes.\n",
    "    height, width : int\n",
    "        Figure size.\n",
    "    \"\"\"\n",
    "    tree = clf.tree_\n",
    "    n_nodes = tree.node_count\n",
    "    children_left = tree.children_left\n",
    "    children_right = tree.children_right\n",
    "    feature = tree.feature\n",
    "    threshold = tree.threshold\n",
    "    impurity = tree.impurity\n",
    "    try:\n",
    "        n_node_samples = tree.n_node_samples\n",
    "    except Exception:\n",
    "        n_node_samples = tree.weighted_n_node_samples.astype(int)\n",
    "\n",
    "    is_classifier = hasattr(clf, 'classes_')\n",
    "    if is_classifier and class_names is None:\n",
    "        class_names = [str(c) for c in getattr(clf, 'classes_', [])]\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'x{idx}' for idx in range(max(0, feature.max()) + 1)] if n_nodes > 0 else []\n",
    "\n",
    "    LEAF = -1\n",
    "    def is_leaf(node):\n",
    "        return children_left[node] == LEAF and children_right[node] == LEAF\n",
    "\n",
    "    # Precompute leaves count per subtree for x-positioning\n",
    "    from functools import lru_cache\n",
    "    @lru_cache(None)\n",
    "    def leaf_count(node):\n",
    "        if node < 0:\n",
    "            return 0\n",
    "        if is_leaf(node) or (max_depth is not None and depth(node) >= max_depth):\n",
    "            return 1\n",
    "        return leaf_count(children_left[node]) + leaf_count(children_right[node])\n",
    "\n",
    "    # Compute depth per node\n",
    "    depths = np.zeros(n_nodes, dtype=int)\n",
    "    def assign_depths(node=0, d=0):\n",
    "        depths[node] = d\n",
    "        if is_leaf(node):\n",
    "            return\n",
    "        if max_depth is not None and d >= max_depth - 1:\n",
    "            return\n",
    "        if children_left[node] != LEAF:\n",
    "            assign_depths(children_left[node], d+1)\n",
    "        if children_right[node] != LEAF:\n",
    "            assign_depths(children_right[node], d+1)\n",
    "    # Helper to query already-computed depth (used by leaf_count)\n",
    "    def depth(node):\n",
    "        return int(depths[node])\n",
    "\n",
    "    if n_nodes == 0:\n",
    "        return go.Figure()\n",
    "\n",
    "    assign_depths(0, 0)\n",
    "\n",
    "    # Compute x positions by allocating horizontal space proportional to leaf counts\n",
    "    xs = np.zeros(n_nodes, dtype=float)\n",
    "    ys = np.zeros(n_nodes, dtype=float)\n",
    "\n",
    "    def assign_positions(node=0, x0=0.0, x1=1.0):\n",
    "        y = -depth(node)\n",
    "        ys[node] = y\n",
    "        if is_leaf(node) or (max_depth is not None and depth(node) >= max_depth):\n",
    "            xs[node] = (x0 + x1) / 2.0\n",
    "            return\n",
    "        lc = leaf_count(children_left[node])\n",
    "        rc = leaf_count(children_right[node])\n",
    "        total = max(lc + rc, 1)\n",
    "        x_mid = x0 + (lc / total) * (x1 - x0)\n",
    "        xs[node] = x_mid\n",
    "        assign_positions(children_left[node], x0, x_mid)\n",
    "        assign_positions(children_right[node], x_mid, x1)\n",
    "\n",
    "    assign_positions(0, 0.0, 1.0)\n",
    "\n",
    "    # Build edge coordinates\n",
    "    edge_x, edge_y = [], []\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaf(i) or (max_depth is not None and depth(i) >= max_depth):\n",
    "            continue\n",
    "        for child in (children_left[i], children_right[i]):\n",
    "            if child == LEAF:\n",
    "                continue\n",
    "            if max_depth is not None and depth(child) >= max_depth + 1:\n",
    "                continue\n",
    "            edge_x += [xs[i], xs[child], None]\n",
    "            edge_y += [ys[i], ys[child], None]\n",
    "\n",
    "    edges = go.Scatter(x=edge_x, y=edge_y, mode='lines', line=dict(color='rgba(150,150,150,0.6)', width=1), hoverinfo='skip')\n",
    "\n",
    "    # Build node labels and colors\n",
    "    texts = []\n",
    "    colors = []\n",
    "    for i in range(n_nodes):\n",
    "        if max_depth is not None and depth(i) >= max_depth and not is_leaf(i):\n",
    "            # Truncated branch node\n",
    "            texts.append(f'Depth {depth(i)} (truncated)')\n",
    "            colors.append('lightgray')\n",
    "            continue\n",
    "        if is_leaf(i):\n",
    "            # value shape: (n_outputs, n_classes) for classifier or (n_outputs, 1) for regressor\n",
    "            val = tree.value[i]\n",
    "            val_str = np.array2string(val.squeeze(), precision=precision, separator=', ')\n",
    "            if is_classifier:\n",
    "                pred_idx = int(np.argmax(val.squeeze()))\n",
    "                pred_name = class_names[pred_idx] if class_names and pred_idx < len(class_names) else str(pred_idx)\n",
    "                txt = f'class: {pred_name}<br>samples: {int(n_node_samples[i])}<br>value: {val_str}'\n",
    "                texts.append(txt)\n",
    "                # simple color palette\n",
    "                palette = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692']\n",
    "                colors.append(palette[pred_idx % len(palette)] if filled else 'white')\n",
    "            else:\n",
    "                pred = float(val.squeeze())\n",
    "                txt = f'value: {pred:.{precision}f}<br>samples: {int(n_node_samples[i])}'\n",
    "                texts.append(txt)\n",
    "                colors.append('#636EFA' if filled else 'white')\n",
    "        else:\n",
    "            fidx = feature[i]\n",
    "            fname = feature_names[fidx] if fidx >= 0 and fidx < len(feature_names) else f'f{fidx}'\n",
    "            thr = threshold[i]\n",
    "            txt = f'{fname} <= {thr:.{precision}f}<br>impurity: {impurity[i]:.{precision}f}<br>samples: {int(n_node_samples[i])}'\n",
    "            texts.append(txt)\n",
    "            colors.append('lightsteelblue')\n",
    "\n",
    "    nodes = go.Scatter(\n",
    "        x=xs, y=ys, mode='markers+text',\n",
    "        marker=dict(size=node_size, color=colors, line=dict(color='black', width=1)),\n",
    "        text=texts, textposition='top center',\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[edges, nodes])\n",
    "    # Format layout: flip y so root at top\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        height=height, width=width,\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, range=[-0.05, 1.05]),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, autorange='reversed')\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plotly_tree_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Train a small tree on the provided Titanic CSV and plot with Plotly\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv('Machine Learning/Classification & Regression/Predicting Housing Prices/DecisionTrees/DecisionTrees_titanic.csv')\n",
    "y = df['Survived']\n",
    "X = df.drop(columns=['Survived'])\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "fig = plot_tree_plotly(clf, feature_names=feature_names, class_names=['Not Survived','Survived'], max_depth=3, precision=2, filled=True)\n",
    "fig.update_layout(title='Decision Tree (Plotly)')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
