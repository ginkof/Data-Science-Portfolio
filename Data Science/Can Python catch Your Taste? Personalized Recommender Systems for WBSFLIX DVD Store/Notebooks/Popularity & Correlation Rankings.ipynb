{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7ed8ba-04b4-4526-b5a4-390ebb1d06fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 Preliminary data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20bfe2ad-aa0e-49d0-b8a8-4f94a632932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "titles = ['links','movies','ratings','tags']\n",
    "path_csv = lambda title: f'/Users/G/Desktop/Documents/Formazione in Data Science/WBS/WBS Bootcamp/8. Recommender Systems/Data/{title}.csv'\n",
    "\n",
    "links = pd.read_csv(path_csv(titles[0]))\n",
    "movies = pd.read_csv(path_csv(titles[1]))\n",
    "ratings = pd.read_csv(path_csv(titles[2]))\n",
    "tags = pd.read_csv(path_csv(titles[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfcf4014-dfc4-4e80-a27c-1227516aa692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>326.127564</td>\n",
       "      <td>19435.295718</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>35530.987199</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>8122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>193609.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
       "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
       "min         1.000000       1.000000       0.500000  8.281246e+08\n",
       "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
       "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
       "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
       "max       610.000000  193609.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32541f62-1a52-405d-a6b4-5b82a15e7257",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Dataframes and Features description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e375a6-bd1c-4927-9987-6146930d9ea1",
   "metadata": {},
   "source": [
    "* `links.csv`: Identifiers that can be used to link to other sources of movie data. Each line of this file after the header row represents one movie\n",
    "    * `imdbId` is an identifier for movies used by <http://www.imdb.com>. E.g., the movie Toy Story has the link <http://www.imdb.com/title/tt0114709/>.\n",
    "\n",
    "    * `tmdbId` is an identifier for movies used by <https://www.themoviedb.org>. E.g., the movie Toy Story has the link <https://www.themoviedb.org/movie/862>.\n",
    "\n",
    "* `ratings.csv`: Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
    "\n",
    "* `tags.csv`: Tags are user-generated metadata about movies. Each tag is typically a single word or short phrase. The meaning, value, and purpose of a particular tag is determined by each user.\n",
    "\n",
    "* `Timestamps`: represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a947abe-8bfc-4f31-89d5-d042f14f92f2",
   "metadata": {},
   "source": [
    "There are no data to impute nor to convert in appropriate datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d44ff68-a037-48ec-9973-a39aa083ea18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Making Recommendations Based on Popularity\n",
    "A popularity-based, non-personalised recommender system that takes as an input the ratings and movies datasets and outputs the “best” movies. How you define “best” is up to you. Those movies will appear as the top row of the WBSFLIX site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e51b67-744f-4157-8b6a-79571f184ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#introduce the average rating and the rating count\n",
    "popularity = ratings[['movieId','rating']].groupby(by='movieId').agg(avg_rating=(\"rating\",\"mean\"))\n",
    "popularity['rating_count'] = ratings[['movieId','rating']].groupby(by='movieId').agg(rating_count=(\"rating\",\"count\"))['rating_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4bc0fff-af66-4bf7-975f-4fceddbcc11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88448</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100556</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rating  rating_count\n",
       "movieId                          \n",
       "88448           5.0             1\n",
       "100556          5.0             1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ordering by avg_rating\n",
    "popularity.sort_values(by='avg_rating',ascending = False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f844f383-d345-4b7b-87ed-ced99a0d28d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>4.164134</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>4.429022</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rating  rating_count\n",
       "movieId                          \n",
       "356        4.164134           329\n",
       "318        4.429022           317"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ordering by counts\n",
    "popularity.sort_values(by='rating_count',ascending = False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ca2ef-516a-4d7b-b822-ccc6a5698ecf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Introducing hybrid metrics\n",
    "\n",
    "* Weighted average\n",
    "$$ w_i = \\frac{ c_i \\cdot r_i}{\\sum_i c_i} $$\n",
    "where $w_i$ is the new hybrid measure, $c_i$ and $r_i$ the counts and rating of the $i$-th system.\n",
    "\n",
    "* Linear combination: we assign different weight to counts and ratings and then sum\n",
    "\n",
    "$$ \\ell_i = a c_i + b r_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d28757-2f69-4d69-b39b-af9903b7daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_hybrid(n,df):\n",
    "    \n",
    "    #this function adds a new column with the weights and returns the \"heaviest\" n resturants\n",
    "    \n",
    "    df2 = df.copy() \n",
    "    df2['weight'] = (df['rating_count'] * df['avg_rating']) / (df['rating_count'].sum())\n",
    "    \n",
    "    return df2.sort_values(by=\"weight\", ascending = False).head(n)\n",
    "\n",
    "#weight_hybrid(10,popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b8e88a-54f8-452b-a032-50844fc6c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_hybrid(n, df, weight_counts):\n",
    "    #This function linearly combines ratings and counts with appropriate weights\n",
    "    \n",
    "    #Error message\n",
    "    if weight_counts < 0 or weight_counts > 1:\n",
    "        print(\"Weight must be in [0, 1]\")\n",
    "    \n",
    "    #Scaling of the data\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    my_scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
    "    my_scaler.fit(df)\n",
    "    df1 = my_scaler.transform(df)\n",
    "    \n",
    "    \n",
    "    col_name = f\"lin. {weight_counts*100}%\"\n",
    "    df1[col_name] = weight_counts * df1['rating_count'] + (1 - weight_counts) * df1['avg_rating']\n",
    "    \n",
    "    return df1.sort_values(by=col_name, ascending=False).head(n)\n",
    "#linear_hybrid(10,popularity, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eddc9771-0c27-4663-8548-8e4768b796d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rating_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating_count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlinear_hybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mlinear_hybrid\u001b[0;34m(n, df, weight_counts)\u001b[0m\n\u001b[1;32m     12\u001b[0m df1 \u001b[38;5;241m=\u001b[39m my_scaler\u001b[38;5;241m.\u001b[39mtransform(df)\n\u001b[1;32m     15\u001b[0m col_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlin. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_counts\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m df1[col_name] \u001b[38;5;241m=\u001b[39m weight_counts \u001b[38;5;241m*\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m weight_counts) \u001b[38;5;241m*\u001b[39m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_rating\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df1\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39mcol_name, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(n)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rating_count'"
     ]
    }
   ],
   "source": [
    "linear_hybrid(10,ratings,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd49504e-f07d-415b-8d95-8afd771939d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_popularity(n, df, weight_counts):\n",
    "    #This function computes the most popular movies based on linear combination method\n",
    "    #This function is an upgrade of linear_hybrid() as it also manipulates the original dataframe\n",
    "    \n",
    "    #introduce the average rating and the rating count\n",
    "    popularity = df[['movieId','rating']].groupby(by='movieId').agg(avg_rating=(\"rating\",\"mean\"))\n",
    "    popularity['rating_count'] = df[['movieId','rating']].groupby(by='movieId').agg(rating_count=(\"rating\",\"count\"))['rating_count']\n",
    "    \n",
    "    \n",
    "    #Scaling of the data\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    my_scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
    "    my_scaler.fit(popularity)\n",
    "    df1 = my_scaler.transform(popularity)\n",
    "    \n",
    "    \n",
    "    col_name = f\"lin. {weight_counts*100}%\"\n",
    "    df1[col_name] = weight_counts * df1['rating_count'] + (1 - weight_counts) * df1['avg_rating']\n",
    "    return df1.sort_values(by=col_name, ascending=False).head(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2f57ee-00e4-4234-b385-7f23322e75b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>lin. 70.0%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.814252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.873116</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.936325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.821571</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.899520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0.813620</td>\n",
       "      <td>0.847561</td>\n",
       "      <td>0.837379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>0.820544</td>\n",
       "      <td>0.844512</td>\n",
       "      <td>0.837322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.829128</td>\n",
       "      <td>0.762195</td>\n",
       "      <td>0.782275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.739102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.722561</td>\n",
       "      <td>0.722459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.667683</td>\n",
       "      <td>0.715711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>0.838430</td>\n",
       "      <td>0.661585</td>\n",
       "      <td>0.714639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_rating  rating_count  lin. 70.0%\n",
       "movieId                                      \n",
       "356        0.814252      1.000000    0.944276\n",
       "318        0.873116      0.963415    0.936325\n",
       "296        0.821571      0.932927    0.899520\n",
       "593        0.813620      0.847561    0.837379\n",
       "2571       0.820544      0.844512    0.837322\n",
       "260        0.829128      0.762195    0.782275\n",
       "110        0.784810      0.719512    0.739102\n",
       "480        0.722222      0.722561    0.722459\n",
       "527        0.827778      0.667683    0.715711\n",
       "2959       0.838430      0.661585    0.714639"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun_popularity(10,ratings,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4b79e-449e-4343-ac8b-7357823775cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Making Recommendations Based on Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2e6f4-8160-424e-ad76-79f544c6ffeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Item-based collaborative filtering\n",
    "\n",
    "A similarity-based, semi-personalised recommender system that takes a movie as an input – when put into production, it will be a movie that the user has watched recently or rated highly, for now, it’s a manually inputted movie – and then outputs a list of movies that are “similar” to the one inputted based on rating correlations from the user-item matrix. Those movies will appear as the second row of the WBSFLIX site.\n",
    "\n",
    "* Create a pivot table userId VS movieId for ratings\n",
    "* Pick up one movieId and calculate the Similarity with the others\n",
    "* Sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cad259-5d97-4036-ba36-131d7ae521f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pivot = pd.pivot_table(data = ratings, values='rating', index='userId', columns='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2cbeca-fbed-4374-822f-01df8d784a42",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1.1 Similarities for a specific movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a2d63-57df-412d-8e2f-55935c2c617c",
   "metadata": {},
   "source": [
    "Based on the previous analysis (linear method) we know that the most popular movie has `movieId=356` (Forrest Gump (1994)).\n",
    "We calculate the correlations with the method `.coorwith()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9404af-00fa-433a-ae6a-70b71579ef2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings_ForrestGump = ratings_pivot[356]\n",
    "similar_to_ForrestGump = ratings_pivot.corrwith(ratings_ForrestGump)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4362b33-80c5-4bc3-8fc3-f8e131da9058",
   "metadata": {},
   "source": [
    "We get wornings due to the NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66519676-ebd5-4bae-a261-62298c9c8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pandas dataframe\n",
    "corr_ForrestGump = pd.DataFrame(similar_to_ForrestGump, columns = ['Pearson'])\n",
    "len0 = len(corr_ForrestGump)\n",
    "#drop the NaNs\n",
    "corr_ForrestGump.dropna(inplace = True)\n",
    "print(f'# of rows before and after dropping NaNs: {len0} -> {len(corr_ForrestGump)}\\n\\n')\n",
    "corr_ForrestGump.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4d913-46e8-4059-89ec-608d118977d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we wanna construct a dataframe of the form (movies) VS (Pearson, popularity_metric)\n",
    "#Notice: we use the previoiusly introduced function linear_hybrid()\n",
    "\n",
    "mixed_ForrestGump = linear_hybrid(len(popularity),popularity, 0.7)[['lin. 70.0%']].join(corr_ForrestGump['Pearson'], how='left')\n",
    "mixed_ForrestGump.drop(356, inplace=True) # drop Forrest Gump itself\n",
    "\n",
    "#The 'lin. 70.0%' column ranges from 0 to ~1.\n",
    "#We filter out all rows below a threshold 0.7 and then keep only the first 10 movies in terms of similatities to Forrest Gump\n",
    "mixed_ForrestGump.loc[mixed_ForrestGump['lin. 70.0%'] > 0.7].sort_values(by='Pearson',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff7ce1-35e6-48c7-8d1a-88592e7a90f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1.2 Similarities for a generic movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33cad9-9268-4a8b-8130-c0118c7344ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I first want a list of movies a user have already seen ordered by rating\n",
    "#Then I'll make a suggestion based on this\n",
    "\n",
    "\n",
    "def favourite_movies(user_id,n,ratings,movies):\n",
    "    best_movieId = ratings.loc[(ratings['userId'] == user_id) & (ratings['userId'] >0)].sort_values(by=\"rating\", ascending=False).head(n)['movieId'].tolist()\n",
    "\n",
    "    best_movies = {}\n",
    "    for movieId in best_movieId:\n",
    "        best_movies[movieId] = movies.loc[movies['movieId'] == movieId, 'title'].iloc[0]\n",
    "    return best_movies\n",
    "favourite_movies(33,10,ratings,movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b6e95-7c8c-48b1-bf1b-59e57e0d89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[movies['movieId']==15,['title']].iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d0272-2d91-483d-97ea-fd5bf9e50415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we condense all the steps above in a unique function\n",
    "# arguments: {movie_name: movie name, n:most similar n-movies}\n",
    "\n",
    "def item_based_collaborative_filtering(movie_name,n):\n",
    "    \n",
    "    #map the movie_name into movieId\n",
    "    movieID = movies.loc[movies['title'] == movie_name,'movieId'].values[0]\n",
    "\n",
    "    #pivot table\n",
    "    ratings_pivot = pd.pivot_table(data = ratings, values='rating', index='userId', columns='movieId')\n",
    "    \n",
    "    #create a pandas df with the correlations of the other movies\n",
    "    similar_to_movieID = ratings_pivot.corrwith(ratings_pivot[movieID])\n",
    "    corr_movieID = pd.DataFrame(similar_to_movieID, columns = ['Pearson'])\n",
    "    corr_movieID.dropna(inplace = True) #drop the NaNs\n",
    "\n",
    "    #Construct a df of (movies) VS (Pearson, popularity_metric)\n",
    "    mixed_movieID = linear_hybrid(len(popularity),popularity, 0.5)[['lin. 50.0%']].join(corr_movieID['Pearson'], how='left')\n",
    "    #Drop movieID\n",
    "    mixed_movieID.drop(movieID, inplace=True)\n",
    "    #We also drop NaNs\n",
    "    mixed_movieID.dropna(inplace = True) #drop the NaNs\n",
    "    #Filter out all rows below a threshold 0.7 and then keep only the first n movies in terms of similatities to movieID\n",
    "    return mixed_movieID.loc[mixed_movieID['lin. 50.0%'] > 0.5].sort_values(by='Pearson',ascending=False).head(n)\n",
    "\n",
    "\n",
    "item_based_collaborative_filtering(\"Father of the Bride Part II (1995)\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747f80e-5783-4292-94d7-316795d76d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_collaborative_filtering(\"Layer Cake (2004)\",6).index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec4638-84a2-4355-a324-3e607312b2f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 User-based collaborative filtering\n",
    "\n",
    "To create a user-based collaborative recommender we are going to go through a very similar process as we did with the item-based recommender. This time though we’re going to calculate the cosine similarity between users, instead of between movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c850a73-0bc8-4f6b-8b44-5a2f115f69ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#create a users-items table\n",
    "user_item = pd.pivot_table(data=ratings, values='rating', index='userId', columns='movieId')\n",
    "\n",
    "#replace NaNs with zeros\n",
    "user_item.fillna(0,inplace=True)\n",
    "\n",
    "#cosine similarities\n",
    "cos_sim = pd.DataFrame(data=cosine_similarity(user_item), index=user_item.index, columns=user_item.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a472d-b86a-4cad-9d35-04adadd88ba2",
   "metadata": {},
   "source": [
    "Let us now focus on one user `uID=30`.\n",
    "\n",
    "The goal is to estimate the numbers where `uID` did not give a rate. So, first of all we have to identify those movies with rating = 0. As a result we get an array of `movieId` which we call missing_movies.\n",
    "\n",
    "For any movie in missing_movies we calculate the estimated rating $r_{\\text{u}_\\text{ID}}$ as\n",
    "\n",
    "$$r_{\\text{u}_\\text{ID}}= \\sum_{i\\neq\\text{u}_\\text{ID}\n",
    "} w_i r_i$$\n",
    "\n",
    "where $r_i$ the true rating of the other users ad $w_i$ is the similarity weight defined as\n",
    "\n",
    "$$w_i = \\frac{c_i}{\\sum_{i\\neq\\text{u}_\\text{ID}}c_i} $$\n",
    "\n",
    "where $c_i$ are is the cosine similarity of the $i$-th user and $w_i$ its weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823cec5-03d0-439f-a6b9-9e1166b9e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "uID = 300\n",
    "\n",
    "#find the unrated movies and the ratings of the other users\n",
    "unseen_rating_uID = user_item.loc[user_item.index!=uID,user_item.loc[uID,:]==0]\n",
    "\n",
    "#calculate weights\n",
    "weights_uID = cos_sim.query('userId!=@uID')[uID]/sum(cos_sim.query('userId!=@uID')[uID])\n",
    "\n",
    "#construct the predicted_rating by means of the dot product\n",
    "predicted_uID = pd.DataFrame(unseen_rating_uID.T.dot(weights_uID), columns = [\"predicted_rate\"]).sort_values(by=\"predicted_rate\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd6a67-4098-467a-bae0-56965f012539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the top 5 UNRATED movies we have to merge our findings with the original table\n",
    "recommendations = predicted_uID.merge(movies, left_index=True, right_on=\"movieId\")\n",
    "recommendations.sort_values(\"predicted_rate\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d051bc-0589-4a9f-8604-fdbbefb92bb8",
   "metadata": {},
   "source": [
    "#### 3.2.1 The function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a92931a-5a88-4c4f-9e94-22e839d6a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_for_you(uID,n):\n",
    "    \n",
    "    #find the unrated movies and the ratings of the other users\n",
    "    unseen_rating_uID = user_item.loc[user_item.index!=uID,user_item.loc[uID,:]==0]\n",
    "    \n",
    "    #calculate weights\n",
    "    weights_uID = cos_sim.query('userId!=@uID')[uID]/sum(cos_sim.query('userId!=@uID')[uID])\n",
    "    \n",
    "    #construct the predicted_rating by means of the dot product\n",
    "    predicted_uID = pd.DataFrame(unseen_rating_uID.T.dot(weights_uID), columns = [\"predicted_rate\"]).sort_values(by=\"predicted_rate\",ascending=False)\n",
    "    \n",
    "    #to find the top 5 UNRATED movies we have to merge our findings with the original table\n",
    "    recommendations = predicted_uID.merge(movies, left_index=True, right_on=\"movieId\")\n",
    "    \n",
    "    return recommendations.sort_values(\"predicted_rate\", ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad9fbc-8f42-4b08-bd6c-8abdb53e94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_for_you(47,5).iloc[:,1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d6723-b153-497d-9eda-65216930bce1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Function for scraping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d18997-8f82-4e24-8ca9-83b2a2c5b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_image(movie_id,links):\n",
    "    try:\n",
    "        # Make the request to the API\n",
    "        endpoint = f'https://api.themoviedb.org/3/movie/{int(links.loc[links[\"movieId\"] == movie_id].iloc[0, 2])}/images?api_key={api_key}'\n",
    "        response = requests.get(endpoint)\n",
    "        data = response.json()\n",
    "\n",
    "        # Get the first image URL from the response\n",
    "        image_url = data['backdrops'][0]['file_path']\n",
    "\n",
    "        # Build the full image URL\n",
    "        image_base_url = 'https://image.tmdb.org/t/p/original'\n",
    "        full_image_url = f'{image_base_url}{image_url}'\n",
    "\n",
    "        # Download the image\n",
    "        response = requests.get(full_image_url)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "\n",
    "        # Resize the image to the desired size\n",
    "        image = image.resize(image_size)\n",
    "\n",
    "        # Create a figure and display the image\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Return the figure\n",
    "        return fig\n",
    "\n",
    "    except:\n",
    "        # If there is an error, display a placeholder image\n",
    "        placeholder_url = f'https://via.placeholder.com/{image_size[0]}x{image_size[1]}?text=Image+Not+Found'\n",
    "        response = requests.get(placeholder_url)\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "\n",
    "        # Resize the placeholder image to the desired size\n",
    "        image = image.resize(image_size)\n",
    "\n",
    "        # Create a figure and display the placeholder image\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Return the figure\n",
    "        return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df073c6d-df0c-4eb0-85a2-a6b0da9d809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQ dictionary\n",
    "faq_dict = {\n",
    "    \"What is your name?\": \"I am ChatBot, your personal movie recommender!\",\n",
    "    \"Tell me a joke\": \"Sure, here you go: Why don't scientists trust atoms? Because they make up everything!\"\n",
    "}\n",
    "\n",
    "def chat_bot():\n",
    "    print(\"Hi! I'm your personal recommender. How can I assist you today?\")\n",
    "    user_input = input().lower()\n",
    "\n",
    "    # Check if user input matches a FAQ question\n",
    "    if user_input in faq_dict:\n",
    "        print(faq_dict[user_input])\n",
    "        return\n",
    "    \n",
    "    print(\"Tell me your userID.\")\n",
    "    try:\n",
    "        user_id = int(input())\n",
    "    except ValueError:\n",
    "        print(\"Please enter a valid user ID.\")\n",
    "        return\n",
    "    \n",
    "    print(\"How many recommendations do you want to get?\")\n",
    "    try:\n",
    "        n = int(input())\n",
    "    except ValueError:\n",
    "        print(\"Please enter a valid number of recommendations.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Here are the recommendations:\")\n",
    "    recommendations = recommend_movies(user_id, n)\n",
    "    \n",
    "    if recommendations.empty:\n",
    "        print(\"No recommendations found.\")\n",
    "        return\n",
    "    \n",
    "    print(recommendations['title'])\n",
    "\n",
    "chat_bot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e4e5d-cae8-4b81-bed1-3ba269a593b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88fd340-ab8b-4fd2-bb7a-e1169ced190a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
